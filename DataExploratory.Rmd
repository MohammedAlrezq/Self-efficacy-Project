---
title: "DataExploratory"
author: "Mohammed Alrezq"
date: "2024-10-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
#Package/libraries 
#install.packages("tidyverse")
library(tidyverse)
#install.packages("cli")
library(cli)
#install.packages("rlang")
library(rlang)
library(psych)# for factor analysis 
library(psychTools)

library(ggplot2)
library (descstat)
library(dplyr)

library(REdaS)# to perform Bartlettâ€™s Test of Sphericity before FA 
library(GPArotation) # required by FA 
library(GGally)
library(lavaan)# used for CFA and SEM modeling 
library(lavaanPlot)
library(semPlot)# also use to build graph for CFA, and SEM
library(caret)
```


```{r cars}
school_model <- read.csv("school_model2.csv")

school_model <- school_model |> 
  select(-1, -13, -14)

names(school_model)
```


```{r}
summary(school_model)
```


```{r}
 
boxplot(school_model)
names(school_model)
school_model_revision <- school_model |> 
  select(-Region)

# Load the required libraries
library(ggplot2)
library(dplyr)
library(tidyr)


# Convert data to long format
data_long <- school_model %>%
  pivot_longer(cols = -Gender, names_to = "Variable", values_to = "Value")
 

# Ensure Gender is treated as a factor
data_long <- data_long %>%
  mutate(Gender = factor(Gender, levels = c(0, 1), labels = c("Female", "Male")))

# Create the boxplot
Bx_plot <- ggplot(data_long, aes(x = Value, y = Variable, fill = Gender)) +
  geom_boxplot() +
  facet_wrap(~ Gender, ncol = 2) +
  labs(
       x = "Scale",
       y = "Variables") +
  scale_fill_manual(values = c("Female" = "gray70", "Male" = "gray30")) +
  theme_minimal()
ggsave("Boxplot-M-F.png", Bx_plot , bg = "white")

```


# all factors 
```{r}
data_long <- school_model %>%
  pivot_longer(cols = everything(), names_to = "Construct", values_to = "Value")

# Create boxplots for each construct
box_All <- ggplot(data_long, aes(x = Construct, y = Value)) +
  geom_boxplot(fill = "gray", color = "black") +
  labs(
    x = "Construct",
    y = "Value"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  coord_flip()


ggsave("Boxplot-All.png", box_All , bg = "white")
```

#Density Plots
```{r}
# Convert data to long format
data_long_density <- school_model %>%
  pivot_longer(cols = everything(), names_to = "Construct", values_to = "Value")

# Create density plots for each construct
ggplot(data_long_density, aes(x = Value, fill = Construct)) +
  geom_density(alpha = 0.6) +
  labs(
    title = "Density Plots of Psychological Constructs",
    x = "Value",
    y = "Density"
  ) +
  theme_minimal() +
  theme(legend.position = "right") +
  scale_fill_manual(values = c("gray20", "gray30", "gray40", "gray50", "gray60", "gray70", "gray80", "gray85", "gray75", "gray65", "gray55"))

```


#histogram for each one 
```{r}
# Convert data to long format
data_long_histogram <- school_model %>%
  pivot_longer(cols = everything(), names_to = "Construct", values_to = "Value")

# Create histograms for each construct using facet_wrap
histrogram_factor<- ggplot(data_long_histogram, aes(x = Value)) +
  geom_histogram(binwidth = 0.3, fill = "gray70", color = "black", alpha = 0.7) +
  facet_wrap(~ Construct, scales = "free", ncol = 3) +
  labs(
    title = "Histograms of Psychological Constructs",
    x = "Value",
    y = "Frequency"
  ) +
  theme_minimal()

ggsave("histrogram_factor.png", histrogram_factor , bg = "white")



histrogram_factor2<-ggplot(data_long_histogram, aes(x = Value)) +
  geom_histogram(binwidth = 0.3, fill = "gray70", color = "black", alpha = 0.7) +
  facet_wrap(~ Construct, scales = "free_y", ncol = 5, strip.position = "top") +
  labs(
    x = "Value",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(
    strip.background = element_rect(fill = "gray85", color = "black"),
    strip.text = element_text(size = 10, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.spacing = unit(1, "lines")
  )

ggsave("histrogram_factor2.png", histrogram_factor2 , bg = "white")











# Create histograms for each construct using facet_wrap with consistent x-axis
ggplot(data_long_histogram, aes(x = Value)) +
  geom_histogram(binwidth = 0.3, fill = "gray70", color = "black", alpha = 0.7) +
  facet_wrap(~ Construct, scales = "free_y", ncol = 4, strip.position = "top") +
  labs(
    title = "Histograms of Psychological Constructs",
    x = "Value",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(
    strip.background = element_rect(fill = "gray85", color = "black"),
    strip.text = element_text(size = 10, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.spacing = unit(1, "lines")
  ) +
  scale_x_continuous(breaks = seq(1, 4, by = 1))
```



# Machine Learning 
# Split data to training and testing and select variables significant based on regression 
```{r}
set.seed(1234)
ind <- sample(2, nrow(school_model), replace = T, prob = c(0.8, 0.2))
train <- school_model[ind == 1,]
test <- school_model[ind == 2,]

#names(school_model)
#write.csv(school_model, "school_model_afterVARNameChange.csv")
#write.csv(school_model, "school_model.csv")
```


# cv SET UP 
```{r}
# Regression Tree
# Bagging
set.seed(1234)
cvcontrol <- trainControl(method="cv", #here used CV (used with regression or classification)
                          number = 10,
                          allowParallel=TRUE)

```

```{r}
##Part 2: Random forest 
# RF: same as DT except change method =RF #-Gender -Relg.Spit -EMP
set.seed(1234)
forest <- train(SEFF ~ .,  
                data=train,
                method="rf", # change the method to RF
                trControl=cvcontrol,
                tuneLength= 12,
                importance=TRUE)
# Plot mtry and find the best value
plot(forest)
forest$bestTune

# re-run the model using (mtry=2)
set.seed(1234)
forest_mtry <- train(SEFF ~ .,  
                data=train,
                method="rf", # change the method to RF
                trControl=cvcontrol,
                tuneLength= 3,
                importance=TRUE)

# plot important variabels 
plot(varImp(forest_mtry))




# Plot, RMSE, R-square based on test data 
set.seed(1234)
rf <-  predict(forest_mtry,  test)
plot(rf ~ test$SEFF, main = 'Predicted Vs Actual MEDV - Test data')
sqrt(mean((test$SEFF - rf)^2))
cor(test$SEFF, rf) ^2

head(rf)
head(school_modelReg$Self.Efc)
# Explain predictions: ML is black box and this give more description about inside
explainer <- lime(test[1:3,], forest, n_bins = 5)
explanation <- explain( x = test[1:3,], 
                        explainer = explainer, 
                        n_features = 5)
plot_features(explanation)
plot_explanations(explanation)


install.packages("rattle")
library(rattle)
fancyRpartPlot(forest$finalModel)

plot(forest$finalModel)

###Random forest based on class note############

library(randomForest)
set.seed(1)
bag.boston=randomForest(Self.Efc~.,data=train,mtry=9,trControl=cvcontrol,
importance=TRUE)
```